{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cntk\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "cntk.cntk_py.set_fixed_random_seed(1) # fix the random seed so that LR examples are repeatable\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Dense(out_dim, activation):\n",
    "    # create the learnable parameters\n",
    "    b = np.zeros(out_dim)\n",
    "    W = np.ndarray((0,out_dim)) # input dimension is unknown\n",
    "    # define the function itself\n",
    "    def dense(x):\n",
    "        if len(W) == 0: # first call: reshape and initialize W\n",
    "            W.resize((x.shape[-1], W.shape[-1]), refcheck=False)\n",
    "            W[:] = np.random.randn(*W.shape) * 0.05\n",
    "        return activation(x.dot(W) + b)\n",
    "    # return as function object: can be called & holds parameters as members\n",
    "    dense.W = W\n",
    "    dense.b = b\n",
    "    return dense\n",
    "\n",
    "d = Dense(5, np.tanh)    # create the function object\n",
    "y = d(np.array([1, 2]))  # apply it like a function\n",
    "W = d.W                  # access member like an object\n",
    "print('W =', d.W)\n",
    "print('y =', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = Dense(5, np.tanh)\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = d(np.array([1, 2]))\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim_lr = 2    # classify 2-dimensional data\n",
    "num_classes_lr = 2  # into one of two classes\n",
    "\n",
    "# This example uses synthetic data from normal distributions,\n",
    "# which we generate in the following.\n",
    "#  X_lr[corpus_size,input_dim] - input data\n",
    "#  Y_lr[corpus_size]           - labels (0 or 1), one-hot-encoded\n",
    "np.random.seed(0)\n",
    "def generate_synthetic_data(N):\n",
    "    Y = np.random.randint(size=N, low=0, high=num_classes_lr)  # labels\n",
    "    X = (np.random.randn(N, input_dim_lr)+3) * (Y[:,None]+1)   # data\n",
    "    # Our model expects float32 features, and cross-entropy\n",
    "    # expects one-hot encoded labels.\n",
    "    Y = scipy.sparse.csr_matrix((np.ones(N,np.float32), (range(N), Y)), shape=(N, num_classes_lr))\n",
    "    X = X.astype(np.float32)\n",
    "    return X, Y\n",
    "X_train_lr, Y_train_lr = generate_synthetic_data(20000)\n",
    "X_test_lr,  Y_test_lr  = generate_synthetic_data(1024)\n",
    "print('data =\\n', X_train_lr[:4])\n",
    "print('labels =\\n', Y_train_lr[:4].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr_factory = cntk.layers.Dense(num_classes_lr, activation=None)\n",
    "x = cntk.input_variable(input_dim_lr)\n",
    "y = cntk.input_variable(num_classes_lr, is_sparse=True)\n",
    "model_lr = model_lr_factory(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@cntk.Function\n",
    "def criterion_lr_factory(data, label_one_hot):\n",
    "    z = model_lr_factory(data)  # apply model. Computes a non-normalized log probability for every output class.\n",
    "    loss = cntk.cross_entropy_with_softmax(z, label_one_hot) # applies softmax to z under the hood\n",
    "    metric = cntk.classification_error(z, label_one_hot)\n",
    "    return loss, metric\n",
    "criterion_lr = criterion_lr_factory(x, y)\n",
    "print('criterion_lr:', criterion_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learner = cntk.sgd(model_lr.parameters,\n",
    "                   cntk.learning_rate_schedule(0.1, cntk.UnitType.minibatch))\n",
    "progress_writer = cntk.logging.ProgressPrinter(0)\n",
    "\n",
    "criterion_lr.train((X_train_lr, Y_train_lr), parameter_learners=[learner],\n",
    "                   callbacks=[progress_writer])\n",
    "\n",
    "print(model_lr.W.value) # peek at updated W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_metric_lr = criterion_lr.test((X_test_lr, Y_test_lr),\n",
    "                                   callbacks=[progress_writer]).metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr = model_lr_factory(x)\n",
    "print('model_lr:', model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "z = model_lr(X_test_lr[:20])\n",
    "print(\"Label    :\", [label.todense().argmax() for label in Y_test_lr[:20]])\n",
    "print(\"Predicted:\", [z[i,:].argmax() for i in range(len(z))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape_mn = (28, 28)  # MNIST digits are 28 x 28\n",
    "num_classes_mn = 10        # classify as one of 10 digits\n",
    "\n",
    "X_train_mn, Y_train_mn = mnist.train.images ,mnist.train.labels\n",
    "X_test_mn, Y_test_mn =mnist.test.images ,mnist.test.labels\n",
    "\n",
    "X_train_mn=X_train_mn.reshape([-1,28,28])\n",
    "X_test_mn=X_test_mn.reshape([-1,28,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the training data.\n",
    "np.random.seed(0) # always use the same reordering, for reproducability\n",
    "idx = np.random.permutation(len(X_train_mn))\n",
    "X_train_mn, Y_train_mn = X_train_mn[idx], Y_train_mn[idx]\n",
    "\n",
    "# Further split off a cross-validation set\n",
    "X_train_mn, X_cv_mn = X_train_mn[:54000], X_train_mn[54000:]\n",
    "Y_train_mn, Y_cv_mn = Y_train_mn[:54000], Y_train_mn[54000:]\n",
    "\n",
    "# Our model expects float32 features, and cross-entropy expects one-hot encoded labels.\n",
    "Y_train_mn, Y_cv_mn, Y_test_mn = (scipy.sparse.csr_matrix((np.ones(len(Y),np.float32), (range(len(Y)), Y)), shape=(len(Y), 10)) for Y in (Y_train_mn, Y_cv_mn, Y_test_mn))\n",
    "X_train_mn, X_cv_mn, X_test_mn = (X.astype(np.float32) for X in (X_train_mn, X_cv_mn, X_test_mn))\n",
    "\n",
    "# Have a peek.\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = (5, 0.5)\n",
    "matplotlib.pyplot.axis('off')\n",
    "_ = matplotlib.pyplot.imshow(np.concatenate(X_train_mn[0:10], axis=1), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_mn_factory():\n",
    "    with cntk.layers.default_options(activation=cntk.ops.relu, pad=False):\n",
    "        return cntk.layers.Sequential([\n",
    "            cntk.layers.Convolution2D((5,5), num_filters=32, reduction_rank=0, pad=True), # reduction_rank=0 for B&W images\n",
    "            cntk.layers.MaxPooling((3,3), strides=(2,2)),\n",
    "            cntk.layers.Convolution2D((3,3), num_filters=48),\n",
    "            cntk.layers.MaxPooling((3,3), strides=(2,2)),\n",
    "            cntk.layers.Convolution2D((3,3), num_filters=64),\n",
    "            cntk.layers.Dense(96),\n",
    "            cntk.layers.Dropout(dropout_rate=0.5),\n",
    "            cntk.layers.Dense(num_classes_mn, activation=None) # no activation in final layer (softmax is done in criterion)\n",
    "        ])\n",
    "model_mn = create_model_mn_factory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@cntk.Function\n",
    "def criterion_mn_factory(data, label_one_hot):\n",
    "    z = model_mn(data)\n",
    "    loss = cntk.cross_entropy_with_softmax(z, label_one_hot)\n",
    "    metric = cntk.classification_error(z, label_one_hot)\n",
    "    return loss, metric\n",
    "x = cntk.input_variable(input_shape_mn)\n",
    "y = cntk.input_variable(num_classes_mn, is_sparse=True)\n",
    "criterion_mn = criterion_mn_factory(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(X_train_mn)\n",
    "lrs = cntk.learning_rate_schedule([0.001]*12 + [0.0005]*6 + [0.00025]*6 + [0.000125]*3 + [0.0000625]*3 + [0.00003125], cntk.learners.UnitType.sample, epoch_size=N)\n",
    "momentums = cntk.learners.momentum_as_time_constant_schedule([0]*5 + [1024], epoch_size=N)\n",
    "minibatch_sizes = cntk.minibatch_size_schedule([256]*6 + [512]*9 + [1024]*7 + [2048]*8 + [4096], epoch_size=N)\n",
    "\n",
    "learner = cntk.learners.momentum_sgd(model_mn.parameters, lrs, momentums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "progress_writer = cntk.logging.ProgressPrinter()\n",
    "criterion_mn.train((X_train_mn, Y_train_mn), minibatch_size=minibatch_sizes,\n",
    "                   max_epochs=40, parameter_learners=[learner], callbacks=[progress_writer])\n",
    "test_metric_mn = criterion_mn.test((X_test_mn, Y_test_mn), callbacks=[progress_writer]).metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
